{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBcAcTJdlifj",
        "outputId": "c2bc53fe-7bad-41c1-efbd-4b22c707ffc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "جاري ربط Google Drive...\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "\n",
            "جاري فك ضغط البيانات...\n",
            "تم فك ضغط البيانات بنجاح.\n",
            "تنبيه: تم استخدام المسار الأساسي (بدون مجلد داخلي).\n",
            "Found 2637 images belonging to 2 classes.\n",
            "Found 660 images belonging to 2 classes.\n",
            "\n",
            "تم حساب أوزان التصنيفات (Class Weights) بنجاح وجاهزية الـ Generators.\n"
          ]
        }
      ],
      "source": [
        "## 1. الإعدادات، استيراد المكتبات، وتجهيز البيانات\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from google.colab import drive\n",
        "\n",
        "# 1. ربط Google Drive\n",
        "print(\"جاري ربط Google Drive...\")\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 2. تحديد المسارات الثابتة\n",
        "DRIVE_ROOT = '/content/drive/MyDrive'\n",
        "PROJECT_FOLDER = 'SmartHospital_SkinClinic'\n",
        "ZIP_FILE_NAME = 'skin_cancer_dataset.zip'\n",
        "EXTRACT_FOLDER = 'skin_data_clinic_prep'\n",
        "zip_path = os.path.join(DRIVE_ROOT, PROJECT_FOLDER, ZIP_FILE_NAME)\n",
        "extract_path = f'/content/{EXTRACT_FOLDER}'\n",
        "\n",
        "# 3. فك ضغط البيانات (لضمان وجود البيانات)\n",
        "print(\"\\nجاري فك ضغط البيانات...\")\n",
        "if not os.path.exists(extract_path):\n",
        "    os.makedirs(extract_path)\n",
        "try:\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_path)\n",
        "    print(\"تم فك ضغط البيانات بنجاح.\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"خطأ: لم يتم العثور على الملف المضغوط في المسار: {zip_path}\")\n",
        "\n",
        "# 4. **ضبط المسار النهائي (DATA_DIR) بناءً على الهيكلية الفعلية**\n",
        "INNER_FOLDER_NAME = 'skin-cancer-malignant-vs-benign' # اسم المجلد الداخلي\n",
        "DATA_DIR = os.path.join(extract_path, INNER_FOLDER_NAME)\n",
        "\n",
        "# التحقق من المسار وتعديله إن لزم (لتفادي أي خطأ)\n",
        "if not os.path.exists(os.path.join(DATA_DIR, 'train')):\n",
        "    # إذا لم يكن المجلد الداخلي موجودًا (أي أن الهيكلية كانت مباشرة)، نعود للمسار الأساسي\n",
        "    DATA_DIR = extract_path\n",
        "    print(\"تنبيه: تم استخدام المسار الأساسي (بدون مجلد داخلي).\")\n",
        "\n",
        "train_path = os.path.join(DATA_DIR, 'train')\n",
        "test_path = os.path.join(DATA_DIR, 'test')\n",
        "\n",
        "# التحقق النهائي من وجود مجلد train قبل إنشاء الـ Generator\n",
        "if not os.path.exists(train_path):\n",
        "    raise FileNotFoundError(f\"خطأ قاتل: مجلد التدريب غير موجود في: {train_path}. يرجى التحقق من هيكل ملف ZIP.\")\n",
        "\n",
        "\n",
        "\n",
        "IMAGE_SIZE = (150, 150)\n",
        "BATCH_SIZE = 32\n",
        "MODEL_SAVE_DIR = os.path.join(DRIVE_ROOT, PROJECT_FOLDER)\n",
        "\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, rotation_range=20, width_shift_range=0.2,\n",
        "                                   height_shift_range=0.2, shear_range=0.2, zoom_range=0.2,\n",
        "                                   horizontal_flip=True, fill_mode='nearest')\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_path, target_size=IMAGE_SIZE, batch_size=BATCH_SIZE, class_mode='binary', shuffle=True\n",
        ")\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_path, target_size=IMAGE_SIZE, batch_size=BATCH_SIZE, class_mode='binary', shuffle=False\n",
        ")\n",
        "\n",
        "counter = train_generator.classes\n",
        "class_weights = class_weight.compute_class_weight(\n",
        "    'balanced',\n",
        "    classes=np.unique(counter),\n",
        "    y=counter\n",
        ")\n",
        "class_weights_dict = dict(enumerate(class_weights))\n",
        "print(\"\\nتم حساب أوزان التصنيفات (Class Weights) بنجاح وجاهزية الـ Generators.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "\n",
        "base_model = MobileNetV2(\n",
        "    weights='imagenet',\n",
        "    include_top=False,\n",
        "    input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3)\n",
        ")\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "x = base_model.output\n",
        "x = Flatten()(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "predictions = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=0.0001),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy', tf.keras.metrics.Precision(name='precision'), tf.keras.metrics.Recall(name='recall')]\n",
        ")\n",
        "\n",
        "checkpoint_filepath = os.path.join(MODEL_SAVE_DIR, 'best_model_weights.weights.h5')\n",
        "if not os.path.exists(MODEL_SAVE_DIR):\n",
        "    os.makedirs(MODEL_SAVE_DIR)\n",
        "\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=5,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "model_checkpoint_callback = ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True\n",
        ")\n",
        "\n",
        "print(\"\\n--- هيكلة MobileNetV2 جاهزة للتدريب السريع ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xE623YemOnK",
        "outputId": "986efbc5-843a-4e29-c831-106685ff6d01"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-608005228.py:7: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "  base_model = MobileNetV2(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
            "\n",
            "--- هيكلة MobileNetV2 جاهزة للتدريب السريع ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ## 3. تدريب النموذج وتطبيق التقنيات المتقدمة\n",
        "\n",
        "# EPOCHS = 15 # عدد Epochs كبير والاعتماد على EarlyStopping للإيقاف\n",
        "\n",
        "# print(\"\\nبدء تدريب النموذج بتطبيق Class Weights و Callbacks...\")\n",
        "# history = model.fit(\n",
        "#     train_generator,\n",
        "#     steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
        "#     epochs=EPOCHS,\n",
        "#     validation_data=test_generator,\n",
        "#     validation_steps=test_generator.samples // BATCH_SIZE,\n",
        "#     callbacks=[early_stopping, model_checkpoint_callback],\n",
        "#     class_weight=class_weights_dict # تطبيق أوزان التصنيفات لضبط الـ Imbalance\n",
        "# )"
      ],
      "metadata": {
        "id": "WQsHJ9EKmT-A"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 3. التدريب الأولي والتعلم المُنقّح (Fine-Tuning)\n",
        "EPOCHS_INITIAL = 10\n",
        "\n",
        "print(\"\\nبدء المرحلة 1: التدريب الأولي السريع...\")\n",
        "history_initial = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // BATCH_SIZE // 2,\n",
        "    epochs=EPOCHS_INITIAL,\n",
        "    validation_data=test_generator,\n",
        "    validation_steps=test_generator.samples // BATCH_SIZE,\n",
        "    callbacks=[early_stopping],\n",
        "    class_weight=class_weights_dict\n",
        ")\n",
        "\n",
        "print(\"\\n✅ انتهاء التدريب الأولي. بدء المرحلة 2: التعلم المُنقّح لزيادة الدقة والـ Recall...\")\n",
        "\n",
        "base_model.trainable = True\n",
        "for layer in base_model.layers[:-50]:\n",
        "    layer.trainable = False\n",
        "\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=0.00001),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy', tf.keras.metrics.Precision(name='precision'), tf.keras.metrics.Recall(name='recall')]\n",
        ")\n",
        "\n",
        "EPOCHS_FINE = 15\n",
        "history_fine = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
        "    epochs=EPOCHS_FINE,\n",
        "    validation_data=test_generator,\n",
        "    validation_steps=test_generator.samples // BATCH_SIZE,\n",
        "    callbacks=[early_stopping, model_checkpoint_callback],\n",
        "    class_weight=class_weights_dict\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SL5XGwV78S9K",
        "outputId": "8828bbae-db6d-4e07-eba6-fb0029e6cc0b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "بدء المرحلة 1: التدريب الأولي السريع...\n",
            "Epoch 1/10\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 1s/step - accuracy: 0.8161 - loss: 0.3974 - precision: 0.7850 - recall: 0.8208 - val_accuracy: 0.8375 - val_loss: 0.3832 - val_precision: 0.7953 - val_recall: 0.8464\n",
            "Epoch 2/10\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 2s/step - accuracy: 0.8098 - loss: 0.4030 - precision: 0.7860 - recall: 0.8335 - val_accuracy: 0.8391 - val_loss: 0.3934 - val_precision: 0.8041 - val_recall: 0.8357\n",
            "Epoch 3/10\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 505ms/step - accuracy: 0.8438 - loss: 0.4393 - precision: 0.8421 - recall: 0.8889 - val_accuracy: 0.8156 - val_loss: 0.4015 - val_precision: 0.8092 - val_recall: 0.7571\n",
            "Epoch 4/10\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 2s/step - accuracy: 0.7973 - loss: 0.4261 - precision: 0.7825 - recall: 0.7631 - val_accuracy: 0.8125 - val_loss: 0.4139 - val_precision: 0.7312 - val_recall: 0.9036\n",
            "Epoch 5/10\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 2s/step - accuracy: 0.8072 - loss: 0.3845 - precision: 0.7620 - recall: 0.8745 - val_accuracy: 0.8250 - val_loss: 0.3846 - val_precision: 0.8529 - val_recall: 0.7250\n",
            "Epoch 6/10\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 482ms/step - accuracy: 0.8438 - loss: 0.4057 - precision: 0.8125 - recall: 0.8667 - val_accuracy: 0.8250 - val_loss: 0.3869 - val_precision: 0.8559 - val_recall: 0.7214\n",
            "\n",
            "✅ انتهاء التدريب الأولي. بدء المرحلة 2: التعلم المُنقّح لزيادة الدقة والـ Recall...\n",
            "Epoch 1/15\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 1s/step - accuracy: 0.8174 - loss: 0.4122 - precision: 0.7802 - recall: 0.8199 - val_accuracy: 0.8406 - val_loss: 0.3747 - val_precision: 0.7890 - val_recall: 0.8679\n",
            "Epoch 2/15\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 396ms/step - accuracy: 0.7500 - loss: 0.5545 - precision: 0.6842 - recall: 0.8667 - val_accuracy: 0.8422 - val_loss: 0.3745 - val_precision: 0.7915 - val_recall: 0.8679\n",
            "Epoch 3/15\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 2s/step - accuracy: 0.8193 - loss: 0.3924 - precision: 0.7819 - recall: 0.8351 - val_accuracy: 0.8531 - val_loss: 0.3644 - val_precision: 0.8163 - val_recall: 0.8571\n",
            "Epoch 4/15\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 241ms/step - accuracy: 0.8750 - loss: 0.2626 - precision: 0.7143 - recall: 1.0000 - val_accuracy: 0.8562 - val_loss: 0.3643 - val_precision: 0.8241 - val_recall: 0.8536\n",
            "Epoch 5/15\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 1s/step - accuracy: 0.8316 - loss: 0.3637 - precision: 0.8051 - recall: 0.8314 - val_accuracy: 0.8469 - val_loss: 0.3738 - val_precision: 0.8370 - val_recall: 0.8071\n",
            "Epoch 6/15\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 232ms/step - accuracy: 0.7500 - loss: 0.4716 - precision: 0.6250 - recall: 0.5000 - val_accuracy: 0.8500 - val_loss: 0.3728 - val_precision: 0.8358 - val_recall: 0.8179\n",
            "Epoch 7/15\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 2s/step - accuracy: 0.8309 - loss: 0.3818 - precision: 0.8037 - recall: 0.8257 - val_accuracy: 0.8438 - val_loss: 0.3628 - val_precision: 0.7941 - val_recall: 0.8679\n",
            "Epoch 8/15\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 256ms/step - accuracy: 0.9375 - loss: 0.2368 - precision: 0.9231 - recall: 0.9231 - val_accuracy: 0.8484 - val_loss: 0.3625 - val_precision: 0.8020 - val_recall: 0.8679\n",
            "Epoch 9/15\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 1s/step - accuracy: 0.8436 - loss: 0.3530 - precision: 0.8096 - recall: 0.8618 - val_accuracy: 0.8594 - val_loss: 0.3607 - val_precision: 0.8167 - val_recall: 0.8750\n",
            "Epoch 10/15\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 264ms/step - accuracy: 0.8125 - loss: 0.3420 - precision: 0.7857 - recall: 0.7857 - val_accuracy: 0.8594 - val_loss: 0.3611 - val_precision: 0.8167 - val_recall: 0.8750\n",
            "Epoch 11/15\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 1s/step - accuracy: 0.8448 - loss: 0.3595 - precision: 0.8159 - recall: 0.8468 - val_accuracy: 0.8469 - val_loss: 0.3735 - val_precision: 0.7917 - val_recall: 0.8821\n",
            "Epoch 12/15\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 241ms/step - accuracy: 0.8438 - loss: 0.2581 - precision: 0.7500 - recall: 0.9231 - val_accuracy: 0.8469 - val_loss: 0.3731 - val_precision: 0.7917 - val_recall: 0.8821\n",
            "Epoch 13/15\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 1s/step - accuracy: 0.8366 - loss: 0.3603 - precision: 0.8031 - recall: 0.8379 - val_accuracy: 0.8500 - val_loss: 0.3587 - val_precision: 0.8087 - val_recall: 0.8607\n",
            "Epoch 14/15\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 171ms/step - accuracy: 0.7812 - loss: 0.4024 - precision: 0.7059 - recall: 0.8571 - val_accuracy: 0.8516 - val_loss: 0.3582 - val_precision: 0.8073 - val_recall: 0.8679\n",
            "Epoch 15/15\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 1s/step - accuracy: 0.8458 - loss: 0.3322 - precision: 0.8010 - recall: 0.8689 - val_accuracy: 0.8625 - val_loss: 0.3462 - val_precision: 0.8137 - val_recall: 0.8893\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 4. التقييم الشاملة الـ Recall، وحفظ النموذج النهائي\n",
        "\n",
        "test_generator.reset()\n",
        "Y_pred = model.predict(test_generator, steps=test_generator.samples // BATCH_SIZE + 1)\n",
        "\n",
        "\n",
        "THRESHOLD = 0.42\n",
        "\n",
        "y_pred = np.where(Y_pred > THRESHOLD, 1, 0)\n",
        "y_true = test_generator.classes[:len(y_pred)]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20su-GRjDrE4",
        "outputId": "36c1fe8a-7c8a-4029-cd08-5148544ec39c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 4s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import numpy as np\n",
        "\n",
        "model.load_weights(checkpoint_filepath)\n",
        "print(\"\\nتم تحميل أفضل الأوزان التي حققت أعلى دقة تحقق بعد مرحلة Fine-Tuning.\")\n",
        "\n",
        "test_generator.reset()\n",
        "Y_pred = model.predict(test_generator, steps=test_generator.samples // BATCH_SIZE + 1)\n",
        "\n",
        "THRESHOLD = 0.42\n",
        "\n",
        "y_pred = np.where(Y_pred > THRESHOLD, 1, 0)\n",
        "y_true = test_generator.classes[:len(y_pred)]\n",
        "\n",
        "print(\"\\n--- تقرير التصنيف الشامل (Classification Report) ---\")\n",
        "# يوضح الـ Accuracy والـ Precision والـ Recall لكل تصنيف (Benign/Malignant)\n",
        "report = classification_report(y_true, y_pred, target_names=['Benign (0)', 'Malignant (1)'], output_dict=True)\n",
        "print(classification_report(y_true, y_pred, target_names=['Benign (0)', 'Malignant (1)']))\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "print(\"\\n--- مصفوفة الارتباك (Confusion Matrix) ---\")\n",
        "print(cm)\n",
        "\n",
        "# 4. استخراج المقاييس النهائية للتقرير ولوحة التحكم\n",
        "accuracy = report['accuracy']\n",
        "f1_score = report['weighted avg']['f1-score']\n",
        "precision_malignant = report['Malignant (1)']['precision']\n",
        "recall_malignant = report['Malignant (1)']['recall']\n",
        "\n",
        "print(f\"\\n=======================================================\")\n",
        "print(f\"✅ Accuracy النهائي: {accuracy:.4f}\")\n",
        "print(f\"✅ Recall (Malignant): {recall_malignant:.4f} (مقياس الكشف عن السرطان)\")\n",
        "print(f\"=======================================================\")\n",
        "print(f\"F1 Score النهائي (Weighted): {f1_score:.4f}\")\n",
        "print(f\"Precision (Malignant): {precision_malignant:.4f}\")\n",
        "\n",
        "\n",
        "# 5. حفظ النموذج النهائي (المُخرج رقم 9)\n",
        "FINAL_MODEL_SAVE_PATH = os.path.join(MODEL_SAVE_DIR, 'skin_cancer_final_model.h5')\n",
        "model.save(FINAL_MODEL_SAVE_PATH)\n",
        "print(f\"\\nتم حفظ النموذج النهائي (skin_cancer_final_model.h5) بنجاح في Drive.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjmgb-rwEcax",
        "outputId": "f5e87eeb-d0b8-4f2d-f39d-d8e9ee7b63bb"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "تم تحميل أفضل الأوزان التي حققت أعلى دقة تحقق بعد مرحلة Fine-Tuning.\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 786ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- تقرير التصنيف الشامل (Classification Report) ---\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "   Benign (0)       0.91      0.80      0.85       360\n",
            "Malignant (1)       0.79      0.90      0.84       300\n",
            "\n",
            "     accuracy                           0.85       660\n",
            "    macro avg       0.85      0.85      0.85       660\n",
            " weighted avg       0.85      0.85      0.85       660\n",
            "\n",
            "\n",
            "--- مصفوفة الارتباك (Confusion Matrix) ---\n",
            "[[289  71]\n",
            " [ 30 270]]\n",
            "\n",
            "=======================================================\n",
            "✅ Accuracy النهائي: 0.8470\n",
            "✅ Recall (Malignant): 0.9000 (مقياس الكشف عن السرطان)\n",
            "=======================================================\n",
            "F1 Score النهائي (Weighted): 0.8472\n",
            "Precision (Malignant): 0.7918\n",
            "\n",
            "تم حفظ النموذج النهائي (skin_cancer_final_model.h5) بنجاح في Drive.\n"
          ]
        }
      ]
    }
  ]
}